{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "V8an-yFwDlVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
        "\n",
        "df_raw = pd.read_csv(\n",
        "    \"AirQualityUCI.csv\",\n",
        "    sep=\";\",\n",
        "    decimal=\",\",\n",
        "    encoding=\"latin1\"\n",
        ")\n",
        "\n",
        "print(\"Raw shape:\", df_raw.shape)\n",
        "\n",
        "df = df_raw.drop(columns=[c for c in df_raw.columns if \"Unnamed\" in c],\n",
        "                 errors=\"ignore\")\n",
        "\n",
        "# HANDLING MISSING DATA\n",
        "df = df.replace(-200, np.nan)\n",
        "\n",
        "# Create timestamp from Date + Time\n",
        "df[\"timestamp\"] = pd.to_datetime(\n",
        "    df[\"Date\"] + \" \" + df[\"Time\"],\n",
        "    format=\"%d/%m/%Y %H.%M.%S\",\n",
        "    errors=\"coerce\"\n",
        ")\n",
        "\n",
        "# Drop rows where timestamp can't be parsed\n",
        "df = df.dropna(subset=[\"timestamp\"])\n",
        "\n",
        "# Sort and set as index\n",
        "df = df.sort_values(\"timestamp\").set_index(\"timestamp\")\n",
        "\n",
        "# Drop original Date/Time columns\n",
        "df = df.drop(columns=[\"Date\", \"Time\"])\n",
        "\n",
        "print(\"After timestamp + sorting:\", df.shape)\n",
        "\n",
        "# DROP NMHC(GT)\n",
        "df = df.drop(columns=[\"NMHC(GT)\"], errors=\"ignore\")\n",
        "\n",
        "# IMPUTE REMAINING NaNs\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Median imputation\n",
        "medians = df[numeric_cols].median()\n",
        "df[numeric_cols] = df[numeric_cols].fillna(medians)\n",
        "\n",
        "# CREATE DERIVED TIME FEATURES\n",
        "df[\"hour\"] = df.index.hour\n",
        "df[\"weekday\"] = df.index.weekday   # 0 = Monday, 6 = Sunday\n",
        "df[\"month\"] = df.index.month\n",
        "df[\"is_weekend\"] = (df[\"weekday\"] >= 5).astype(int)\n",
        "\n",
        "# Cyclical encoding\n",
        "df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
        "df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
        "df[\"weekday_sin\"] = np.sin(2 * np.pi * df[\"weekday\"] / 7)\n",
        "df[\"weekday_cos\"] = np.cos(2 * np.pi * df[\"weekday\"] / 7)\n",
        "\n",
        "# LAGS & MOVING AVERAGES\n",
        "pollutants = [\"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]\n",
        "pollutants = [p for p in pollutants if p in df.columns]\n",
        "\n",
        "# hours\n",
        "lags = [1, 6, 12, 24]\n",
        "# moving avgs\n",
        "ma_windows = [6, 24]\n",
        "\n",
        "for col in pollutants:\n",
        "    for lag in lags:\n",
        "        df[f\"{col}_lag_{lag}h\"] = df[col].shift(lag)\n",
        "\n",
        "    for w in ma_windows:\n",
        "        df[f\"{col}_ma_{w}h\"] = df[col].rolling(window=w, min_periods=1).mean()\n",
        "\n",
        "\n",
        "# SCALING FEATURES\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "df_model = df.dropna()\n",
        "\n",
        "print(\"Final modelling dataset shape:\", df_model.shape)\n",
        "df_model.head()\n",
        "\n",
        "df_model.to_csv(\"AirQuality_cleaned.csv\", index=True)\n",
        "print(\"AirQuality_cleaned.csv has been saved for future use.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRbzojQgDc3a",
        "outputId": "06389e9b-ccd9-45d0-bf64-7bd6dab7dca2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw shape: (9471, 17)\n",
            "After timestamp + sorting: (9357, 13)\n",
            "Final modelling dataset shape: (9333, 44)\n",
            "AirQuality_cleaned.csv has been saved for future use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main Code**"
      ],
      "metadata": {
        "id": "4c6GFH9eDojK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX-k52cTDWZG",
        "outputId": "948d75a7-78d6-43fc-fd9d-d5eb9619e917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Split Info:\n",
            "   Train (2004): 7110 samples\n",
            "   Test  (2005): 2247 samples\n",
            "\n",
            "ðŸ“‚ Output Folder Created: model_output_2\n",
            "   All plots and tables will be saved here silently.\n",
            "\n",
            "ðŸš€ Starting Training Loop...\n",
            "Training LinearRegression...\n",
            "Training RandomForest...\n",
            "Training XGBoost...\n",
            "\n",
            "==================================================\n",
            "ðŸ† FINAL TEST SET PERFORMANCE TABLE\n",
            "==================================================\n",
            "                             MAE  RMSE    R2\n",
            "Pollutant Model                             \n",
            "C6H6(GT)  LinearRegression 0.550 0.566 0.580\n",
            "          RandomForest     0.063 0.087 0.990\n",
            "          XGBoost          0.031 0.039 0.998\n",
            "CO(GT)    LinearRegression 0.592 0.670 0.559\n",
            "          RandomForest     0.284 0.424 0.823\n",
            "          XGBoost          0.257 0.392 0.849\n",
            "NO2(GT)   LinearRegression 0.361 0.496 0.815\n",
            "          RandomForest     0.638 0.853 0.453\n",
            "          XGBoost          0.493 0.723 0.607\n",
            "NOx(GT)   LinearRegression 0.312 0.442 0.830\n",
            "          RandomForest     0.332 0.476 0.803\n",
            "          XGBoost          0.264 0.423 0.844\n",
            "==================================================\n",
            "\n",
            "âœ… Table saved to CSV: model_output_2/final_performance_table.csv\n",
            "\n",
            "Generating detailed plots for the optimal model (saving silently)...\n",
            "-> Optimal Algorithm selected: XGBoost (Avg R2: 0.824)\n",
            "âœ… All processes complete. All graphs saved in folder: model_output_2\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. INSTALL & IMPORTS\n",
        "# ==========================================\n",
        "# Install required packages silently\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Import all necessary metrics\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from xgboost import XGBRegressor\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "# Set seaborn theme for cleaner plots and tables\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "# Set pandas option to display numbers nicely in the final table\n",
        "pd.set_option('display.float_format', '{:.3f}'.format)\n",
        "\n",
        "# ==========================================\n",
        "# 3. SPLITTING (TRAIN vs TEST)\n",
        "# ==========================================\n",
        "# NOTE: Assuming 'df' is already loaded in your environment.\n",
        "train_df = df[df.index.year == 2004]\n",
        "test_df = df[df.index.year == 2005]\n",
        "\n",
        "# Define target columns\n",
        "target_cols = [\"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]\n",
        "target_cols = [c for c in target_cols if c in df.columns]\n",
        "feature_cols = [c for c in df.columns if c not in target_cols]\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[target_cols]\n",
        "X_test = test_df[feature_cols]\n",
        "y_test = test_df[target_cols]\n",
        "\n",
        "# Validation set for XGBoost (last 15% of training data)\n",
        "val_split_idx = int(len(X_train) * 0.85)\n",
        "X_train_sub = X_train.iloc[:val_split_idx]\n",
        "y_train_sub = y_train.iloc[:val_split_idx]\n",
        "X_val = X_train.iloc[val_split_idx:]\n",
        "y_val = y_train.iloc[val_split_idx:]\n",
        "\n",
        "print(f\"ðŸ“Š Split Info:\")\n",
        "print(f\"   Train (2004): {len(X_train)} samples\")\n",
        "print(f\"   Test  (2005): {len(X_test)} samples\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. MODEL DEFINITIONS\n",
        "# ==========================================\n",
        "models = {\n",
        "    \"LinearRegression\": Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('regressor', LinearRegression())\n",
        "    ]),\n",
        "    \"RandomForest\": Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42))\n",
        "    ]),\n",
        "    \"XGBoost\": XGBRegressor(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        tree_method=\"auto\",\n",
        "        missing=np.nan,\n",
        "        early_stopping_rounds=50  # <--- FIXED: Moved here from .fit()\n",
        "    )\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 4.5 FOLDER CREATION LOGIC\n",
        "# ==========================================\n",
        "base_folder_name = \"model_output\"\n",
        "output_folder = base_folder_name\n",
        "counter = 1\n",
        "\n",
        "# Check if folder exists, if so, increment number\n",
        "while os.path.exists(output_folder):\n",
        "    output_folder = f\"{base_folder_name}_{counter}\"\n",
        "    counter += 1\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(f\"\\nðŸ“‚ Output Folder Created: {output_folder}\")\n",
        "print(\"   All plots and tables will be saved here silently.\")\n",
        "\n",
        "# ==========================================\n",
        "# 5. TRAINING & EVALUATION LOOP\n",
        "# ==========================================\n",
        "results_list = []\n",
        "# Dictionary to store predictions for final best model analysis\n",
        "final_predictions = {}\n",
        "\n",
        "print(\"\\nðŸš€ Starting Training Loop...\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    try:\n",
        "        if name == \"XGBoost\":\n",
        "            # FIXED: Removed early_stopping_rounds from here\n",
        "            model.fit(\n",
        "                X_train_sub, y_train_sub,\n",
        "                eval_set=[(X_val, y_val)],\n",
        "                verbose=False\n",
        "            )\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Store predictions\n",
        "        final_predictions[name] = y_pred\n",
        "\n",
        "        # Ensure shape consistency\n",
        "        if y_pred.ndim == 1:\n",
        "            y_pred = y_pred.reshape(-1, 1)\n",
        "\n",
        "        # Calculate Metrics & Plot per Target\n",
        "        for i, target_col in enumerate(y_test.columns):\n",
        "            y_true_col = y_test[target_col].values\n",
        "            y_pred_col = y_pred[:, i]\n",
        "\n",
        "            # Calculate Metrics (MAE, RMSE, R2)\n",
        "            mae = mean_absolute_error(y_true_col, y_pred_col)\n",
        "            rmse = np.sqrt(mean_squared_error(y_true_col, y_pred_col))\n",
        "            r2 = r2_score(y_true_col, y_pred_col)\n",
        "\n",
        "            results_list.append({\n",
        "                \"Model\": name,\n",
        "                \"Pollutant\": target_col,\n",
        "                \"MAE\": mae,\n",
        "                \"RMSE\": rmse,\n",
        "                \"R2\": r2\n",
        "            })\n",
        "\n",
        "            # --- SILENT PLOTTING (Save and Close, No Show) ---\n",
        "            clean_target = target_col.replace(\"(\", \"\").replace(\")\", \"\")\n",
        "\n",
        "            # 1. Residual Line Plot\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            residuals = y_true_col - y_pred_col\n",
        "            plt.plot(residuals, label='Residuals', alpha=0.6, linewidth=0.8, color='steelblue')\n",
        "            plt.axhline(0, color='red', linestyle='--')\n",
        "            plt.title(f\"{name} - {target_col} - Residuals over Time\")\n",
        "            plt.ylabel(\"Error\")\n",
        "            plt.xlabel(\"Test Samples\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            # Save and close immediately\n",
        "            plt.savefig(os.path.join(output_folder, f\"{name}_{clean_target}_Res_Line.png\"))\n",
        "            plt.close()\n",
        "\n",
        "            # 2. Trend Plot (First 200 hours for visibility)\n",
        "            plt.figure(figsize=(10, 4))\n",
        "            plt.plot(y_true_col[:200], label='Actual', color='black', linewidth=1.5)\n",
        "            plt.plot(y_pred_col[:200], label='Predicted', color='darkorange', alpha=0.8, linewidth=1.5)\n",
        "            plt.title(f\"{name} - {target_col} - Trend (First 200 Hrs)\")\n",
        "            plt.ylabel(\"Concentration\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            # Save and close immediately\n",
        "            plt.savefig(os.path.join(output_folder, f\"{name}_{clean_target}_Trend.png\"))\n",
        "            plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Failed to train {name}: {e}\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. FINAL SUMMARY TABLE (PRINTED)\n",
        "# ==========================================\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ðŸ† FINAL TEST SET PERFORMANCE TABLE\")\n",
        "print(\"=\"*50)\n",
        "results_df = pd.DataFrame(results_list)\n",
        "\n",
        "# Format table structure (MultiIndex on Pollutant, then Model)\n",
        "summary_table = results_df.set_index(['Pollutant', 'Model']).sort_index()\n",
        "\n",
        "# PRINT THE TABLE\n",
        "print(summary_table)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Save table to CSV as well\n",
        "table_path = os.path.join(output_folder, \"final_performance_table.csv\")\n",
        "summary_table.to_csv(table_path)\n",
        "print(f\"\\nâœ… Table saved to CSV: {table_path}\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# 7. BEST MODEL DETAILED PLOTS (SILENT SAVE)\n",
        "# ==========================================\n",
        "print(\"\\nGenerating detailed plots for the optimal model (saving silently)...\")\n",
        "\n",
        "# Determine best model based on highest average R2 across all pollutants\n",
        "avg_r2_per_model = results_df.groupby('Model')['R2'].mean()\n",
        "best_model_name = avg_r2_per_model.idxmax()\n",
        "best_model_score = avg_r2_per_model.max()\n",
        "\n",
        "print(f\"-> Optimal Algorithm selected: {best_model_name} (Avg R2: {best_model_score:.3f})\")\n",
        "\n",
        "# Retrieve predictions for the best model\n",
        "best_preds_arr = final_predictions[best_model_name]\n",
        "\n",
        "# Loop through targets to generate specific plots for the best model\n",
        "for i, target_col in enumerate(y_test.columns):\n",
        "    y_true_col = y_test[target_col].values\n",
        "    y_pred_col = best_preds_arr[:, i]\n",
        "    clean_target = target_col.replace(\"(\", \"\").replace(\")\", \"\")\n",
        "\n",
        "    # Calculate residuals\n",
        "    residuals = y_true_col - y_pred_col\n",
        "\n",
        "    # --- Plot A: Predicted vs True Scatter ---\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(y_true_col, y_pred_col, alpha=0.5, edgecolors='k', s=30, color='steelblue')\n",
        "    # Add identity line\n",
        "    fit_min = min(y_true_col.min(), y_pred_col.min())\n",
        "    fit_max = max(y_true_col.max(), y_pred_col.max())\n",
        "    plt.plot([fit_min, fit_max], [fit_min, fit_max], 'r--', lw=2, label='Perfect Prediction')\n",
        "    plt.title(f\"{best_model_name} - {target_col}\\nPredicted vs True\")\n",
        "    plt.xlabel(\"True Value\")\n",
        "    plt.ylabel(\"Predicted Value\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    # Save and close (silent)\n",
        "    plt.savefig(os.path.join(output_folder, f\"BEST_{best_model_name}_{clean_target}_PredVsTrue.png\"))\n",
        "    plt.close()\n",
        "\n",
        "    # --- Plot B: Residual Distribution Histogram ---\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(residuals, kde=True, bins=30, color='steelblue', edgecolor='k')\n",
        "    plt.axvline(0, color='red', linestyle='--', lw=2)\n",
        "    plt.title(f\"{best_model_name} - {target_col}\\nResidual Distribution\")\n",
        "    plt.xlabel(\"Residual (True - Pred)\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.tight_layout()\n",
        "    # Save and close (silent)\n",
        "    plt.savefig(os.path.join(output_folder, f\"BEST_{best_model_name}_{clean_target}_Res_Hist.png\"))\n",
        "    plt.close()\n",
        "\n",
        "print(f\"âœ… All processes complete. All graphs saved in folder: {output_folder}\")"
      ]
    }
  ]
}